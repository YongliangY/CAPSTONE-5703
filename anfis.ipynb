{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#remove first three colums\n",
        "import pandas as pd\n",
        "\n",
        "# Load the Excel file\n",
        "file_path = \"/content/database.xlsx\"  # Use the full path if needed\n",
        "df = pd.read_excel(file_path)\n",
        "sheet_name = \"Maintable (M1) (CORRECTED)\"\n",
        "df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
        "\n",
        "# Drop the first three columns\n",
        "df_processed = df.iloc[:, 3:]\n",
        "\n",
        "# Separate features and label\n",
        "# Step 1: Drop rows with missing or invalid labels\n",
        "df_processed = df_processed.dropna(subset=[\"failure_mode\"]).reset_index(drop=True)\n",
        "\n",
        "# Step 2: Encode the labels\n",
        "df_processed[\"failure_mode_cat\"] = df_processed[\"failure_mode\"].astype(\"category\").cat.codes\n",
        "y = df_processed[\"failure_mode_cat\"]\n",
        "\n",
        "# Step 3: Drop any remaining -1 (just in case)\n",
        "valid_indices = y[y != -1].index\n",
        "X = df_processed.drop(columns=[\"failure_mode\", \"failure_mode_cat\"]).iloc[valid_indices]\n",
        "y = y.iloc[valid_indices].reset_index(drop=True)\n",
        "\n",
        "# Combine X and y first to ensure labels stay matched\n",
        "df_clean = pd.concat([X, y], axis=1)\n",
        "df_clean = df_clean.dropna().reset_index(drop=True)\n",
        "\n",
        "# Separate again\n",
        "X = df_clean.drop(columns=[y.name])\n",
        "y = df_clean[y.name]\n",
        "\n",
        "\n",
        "# (Optional) Display the first few rows of features and label\n",
        "print(X.head())\n",
        "print(y.head())\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueft-ASGXJ5C",
        "outputId": "a787d370-04dc-453d-e56b-4014f4dc68ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      tw    lw       hw  M/(V.lw)     hw/lw  P/(Ag.fc)    fc      Agb  \\\n",
            "0  150.0  1000   2200.0      2.20  2.200000       0.00  30.5  30000.0   \n",
            "1  150.0  1400   2000.0      1.43  1.428571       0.01  46.8      0.0   \n",
            "2  150.0  1400   2000.0      1.43  1.428571       0.01  46.6      0.0   \n",
            "3  127.0  1625  12000.0      7.38  7.384615       0.10  49.0  77140.0   \n",
            "4  100.0   700   1600.0      2.50  2.285714       0.15  27.4  10000.0   \n",
            "\n",
            "         Ag    Agb/Ag   ρbl.fybl  ρsh.fysh    ρl.fyl    ρt.fyt  v_test  \n",
            "0  150000.0  0.200000   5.652500  7.395000  2.847500  3.740000  155.15  \n",
            "1  210000.0  0.000000   0.000000  0.000000  4.410368  2.021229  666.82  \n",
            "2  210000.0  0.000000   0.000000  0.000000  7.725619  2.021229  787.40  \n",
            "3  309093.0  0.249569   2.956163  2.667677  1.219476  1.177428  144.75  \n",
            "4   70000.0  0.142857  14.732880  0.000000  2.673600  2.655481  143.15  \n",
            "0    2\n",
            "1    2\n",
            "2    0\n",
            "3    2\n",
            "4    1\n",
            "Name: failure_mode_cat, dtype: int8\n",
            "(470, 15)\n",
            "(470,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# Apply Min-Max normalization to features\n",
        "scaler = MinMaxScaler()\n",
        "X_normalized = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
        "\n",
        "print(X_normalized.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqzmp8G9YDaS",
        "outputId": "24f3f711-8581-4add-ea13-9fab0e670a94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         tw        lw        hw  M/(V.lw)     hw/lw  P/(Ag.fc)        fc  \\\n",
            "0  0.471831  0.193548  0.172996  0.273492  0.273315   0.000000  0.145026   \n",
            "1  0.471831  0.322581  0.156118  0.165498  0.165191   0.019983  0.275270   \n",
            "2  0.471831  0.322581  0.156118  0.165498  0.165191   0.019983  0.273672   \n",
            "3  0.390845  0.395161  1.000000  1.000000  1.000000   0.199833  0.292849   \n",
            "4  0.295775  0.096774  0.122363  0.315568  0.285329   0.299749  0.120256   \n",
            "\n",
            "        Agb        Ag    Agb/Ag  ρbl.fybl  ρsh.fysh    ρl.fyl    ρt.fyt  \\\n",
            "0  0.100000  0.205003  0.351200  0.051531  0.164410  0.117031  0.265415   \n",
            "1  0.000000  0.295860  0.000000  0.000000  0.000000  0.181264  0.143440   \n",
            "2  0.000000  0.295860  0.000000  0.000000  0.000000  0.317518  0.143440   \n",
            "3  0.257133  0.445914  0.438243  0.026950  0.059309  0.050120  0.083558   \n",
            "4  0.033333  0.083861  0.250857  0.134313  0.000000  0.109883  0.188451   \n",
            "\n",
            "     v_test  \n",
            "0  0.049663  \n",
            "1  0.231365  \n",
            "2  0.274185  \n",
            "3  0.045970  \n",
            "4  0.045402  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#train test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
        "import numpy as np\n",
        "\n",
        "print(\"X has NaNs?\", np.isnan(X_train.to_numpy()).any())\n",
        "print(\"X has Infs?\", np.isinf(X_train.to_numpy()).any())\n",
        "print(\"y has NaNs?\", np.isnan(y_train.to_numpy()).any())\n",
        "print(\"y has Infs?\", np.isinf(y_train.to_numpy()).any())\n"
      ],
      "metadata": {
        "id": "yltiaJBaZEPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99531ce0-f6f2-4299-9929-fd81d2dee988"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X has NaNs? False\n",
            "X has Infs? False\n",
            "y has NaNs? False\n",
            "y has Infs? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "\n",
        "class GaussianMF(nn.Module):\n",
        "    def __init__(self, n_features, n_mfs):\n",
        "        super().__init__()\n",
        "        self.centers = nn.Parameter(torch.rand(n_features, n_mfs))\n",
        "        self.sigmas = nn.Parameter(torch.rand(n_features, n_mfs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)  # (batch, features, 1)\n",
        "        centers = self.centers.unsqueeze(0)  # (1, features, mfs)\n",
        "        sigmas = self.sigmas.unsqueeze(0)\n",
        "        return torch.exp(-((x - centers) ** 2) / (2 * sigmas ** 2))  # (batch, features, mfs)\n",
        "\n",
        "class SimpleANFIS(nn.Module):\n",
        "    def __init__(self, n_inputs, n_rules_per_input, n_classes):\n",
        "        super().__init__()\n",
        "        self.n_inputs = n_inputs\n",
        "        self.n_rules_per_input = n_rules_per_input\n",
        "        self.total_rules = n_rules_per_input ** n_inputs\n",
        "        self.n_classes = n_classes\n",
        "\n",
        "        self.mf = GaussianMF(n_inputs, n_rules_per_input)\n",
        "        self.rule_weights = nn.Parameter(torch.rand(self.total_rules))\n",
        "        self.linear = nn.Linear(self.total_rules, n_classes)\n",
        "\n",
        "        # All rule combinations, e.g., [(0,0), (0,1), ..., (1,1)]\n",
        "        self.rule_indices = torch.tensor(\n",
        "            list(itertools.product(range(n_rules_per_input), repeat=n_inputs))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        mf_out = self.mf(x)  # (batch, n_inputs, n_rules_per_input)\n",
        "        batch_size = x.shape[0]\n",
        "        rules = []\n",
        "\n",
        "        for rule in self.rule_indices:\n",
        "            selected = []\n",
        "            for i, mf_idx in enumerate(rule):\n",
        "                selected.append(mf_out[:, i, mf_idx])\n",
        "            rule_strength = torch.stack(selected, dim=1).prod(dim=1)  # (batch,)\n",
        "            rules.append(rule_strength)\n",
        "\n",
        "        rules = torch.stack(rules, dim=1)  # (batch, total_rules)\n",
        "        weights = F.softmax(self.rule_weights, dim=0)\n",
        "        combined = rules * weights  # (batch, total_rules)\n",
        "        return self.linear(combined)  # (batch, n_classes)\n"
      ],
      "metadata": {
        "id": "JFDhJDRHlNw1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup\n",
        "n_classes = y.nunique()\n",
        "\n",
        "# Convert data\n",
        "X_train_tensor = torch.tensor(X_train.to_numpy(), dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test.to_numpy(), dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.to_numpy(), dtype=torch.long)\n",
        "y_test_tensor = torch.tensor(y_test.to_numpy(), dtype=torch.long)\n",
        "\n",
        "# Create model\n",
        "model = SimpleANFIS(n_inputs=X_train.shape[1], n_rules_per_input=2, n_classes=n_classes)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train loop\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X_train_tensor)  # logits\n",
        "    loss = loss_fn(output, y_train_tensor)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvnBiYhNlRrn",
        "outputId": "b1e7154f-db12-4400-c3be-f63b578d027d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 1.0982\n",
            "Epoch 2, Loss: 1.0967\n",
            "Epoch 3, Loss: 1.0953\n",
            "Epoch 4, Loss: 1.0939\n",
            "Epoch 5, Loss: 1.0927\n",
            "Epoch 6, Loss: 1.0916\n",
            "Epoch 7, Loss: 1.0905\n",
            "Epoch 8, Loss: 1.0896\n",
            "Epoch 9, Loss: 1.0887\n",
            "Epoch 10, Loss: 1.0879\n",
            "Epoch 11, Loss: 1.0872\n",
            "Epoch 12, Loss: 1.0866\n",
            "Epoch 13, Loss: 1.0860\n",
            "Epoch 14, Loss: 1.0855\n",
            "Epoch 15, Loss: 1.0850\n",
            "Epoch 16, Loss: 1.0845\n",
            "Epoch 17, Loss: 1.0840\n",
            "Epoch 18, Loss: 1.0836\n",
            "Epoch 19, Loss: 1.0831\n",
            "Epoch 20, Loss: 1.0826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(X_test_tensor).argmax(dim=1)\n",
        "    acc = accuracy_score(y_test_tensor, preds)\n",
        "    print(\"Test Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5AeIBIAq855",
        "outputId": "4833c1fa-d76c-4b63-eb1d-628258a6a19d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.43617021276595747\n"
          ]
        }
      ]
    }
  ]
}