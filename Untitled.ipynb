{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fbedb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel 文件中的列名：\n",
      "['Paper No', 'Specimen', 'conformity_tbec2018', 'tw', 'lw', 'hw', 'M/(V.lw)', 'hw/lw', 'P/(Ag.fc)', 'fc', 'Agb', 'Ag', 'Agb/Ag', 'ρbl.fybl', 'ρsh.fysh', 'ρl.fyl', 'ρt.fyt', 'v_test', 'failure_mode']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载 Excel 文件数据（请确保路径正确）\n",
    "data = pd.read_excel(\"database.xlsx\")\n",
    "\n",
    "# 打印所有列名，确认实际的列名称\n",
    "print(\"Excel 文件中的列名：\")\n",
    "print(data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0d9afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预览：\n",
      "                      Paper No                   Specimen  \\\n",
      "0  Abdulridha & Palermo (2017)                      W1-SR   \n",
      "1      [114] Adajar et al.1995                       RCW1   \n",
      "2                          NaN                       RCW3   \n",
      "3             [98] Adebar,2007  High-Rise Core Wall (265)   \n",
      "4            [26] Alarcon,2014                    W1 (49)   \n",
      "\n",
      "   conformity_tbec2018     tw    lw       hw  M/(V.lw)     hw/lw  P/(Ag.fc)  \\\n",
      "0                  0.0  150.0  1000   2200.0      2.20  2.200000       0.00   \n",
      "1                  0.0  150.0  1400   2000.0      1.43  1.428571       0.01   \n",
      "2                  0.0  150.0  1400   2000.0      1.43  1.428571       0.01   \n",
      "3                  0.0  127.0  1625  12000.0      7.38  7.384615       0.10   \n",
      "4                  0.0  100.0   700   1600.0      2.50  2.285714       0.15   \n",
      "\n",
      "     fc      Agb        Ag    Agb/Ag   ρbl.fybl  ρsh.fysh    ρl.fyl    ρt.fyt  \\\n",
      "0  30.5  30000.0  150000.0  0.200000   5.652500  7.395000  2.847500  3.740000   \n",
      "1  46.8      0.0  210000.0  0.000000   0.000000  0.000000  4.410368  2.021229   \n",
      "2  46.6      0.0  210000.0  0.000000   0.000000  0.000000  7.725619  2.021229   \n",
      "3  49.0  77140.0  309093.0  0.249569   2.956163  2.667677  1.219476  1.177428   \n",
      "4  27.4  10000.0   70000.0  0.142857  14.732880  0.000000  2.673600  2.655481   \n",
      "\n",
      "   v_test  failure_mode  \n",
      "0  155.15           3.0  \n",
      "1  666.82           3.0  \n",
      "2  787.40           1.0  \n",
      "3  144.75           3.0  \n",
      "4  143.15           2.0  \n",
      "训练集样本数： 397\n",
      "测试集样本数： 100\n",
      "输入特征数： 15\n",
      "目标类别数： 3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 1. 从 Excel 文件加载数据\n",
    "# 请确保database.xlsx与该脚本在同一目录下\n",
    "data = pd.read_excel(\"database.xlsx\")\n",
    "\n",
    "# 查看数据基本信息，确认列名称\n",
    "print(\"数据预览：\")\n",
    "print(data.head())\n",
    "\n",
    "# 2. 分离特征和目标变量\n",
    "# 假设输入特征列名称如下（根据实际数据调整）\n",
    "feature_cols = ['tw', 'lw', 'hw', 'M/(V.lw)', 'hw/lw', 'P/(Ag.fc)', 'fc', 'Agb', 'Ag', 'Agb/Ag', 'ρbl.fybl', 'ρsh.fysh', 'ρl.fyl', 'ρt.fyt', 'v_test']\n",
    "\n",
    "# 目标变量列名称（请根据实际情况修改）\n",
    "target_col = \"failure_mode\"\n",
    "\n",
    "# 获取输入特征 X 和目标变量 y\n",
    "X = data[feature_cols].values\n",
    "y = data[target_col].values\n",
    "\n",
    "# 3. 对输入特征进行归一化处理，将特征缩放到[-1, 1]区间\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 4. 对目标变量进行独热编码\n",
    "# 首先对目标类别进行编码（如果目标为字符串形式）\n",
    "y_encoded = pd.get_dummies(y).values\n",
    "# 或者使用to_categorical（如果先将目标转换为数值型标签）\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# y_int = le.fit_transform(y)\n",
    "# y_encoded = to_categorical(y_int)\n",
    "\n",
    "# 5. 划分训练集和测试集（例如80%训练，20%测试）\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 输出数据维度以确认处理无误\n",
    "print(\"训练集样本数：\", X_train.shape[0])\n",
    "print(\"测试集样本数：\", X_test.shape[0])\n",
    "print(\"输入特征数：\", X_train.shape[1])\n",
    "print(\"目标类别数：\", y_train.shape[1])\n",
    "\n",
    "# 保存预处理后的数据（可选）\n",
    "np.save(\"X_train.npy\", X_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_test.npy\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bc14a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预览：\n",
      "                      Paper No                   Specimen  \\\n",
      "0  Abdulridha & Palermo (2017)                      W1-SR   \n",
      "1      [114] Adajar et al.1995                       RCW1   \n",
      "2                          NaN                       RCW3   \n",
      "3             [98] Adebar,2007  High-Rise Core Wall (265)   \n",
      "4            [26] Alarcon,2014                    W1 (49)   \n",
      "\n",
      "   conformity_tbec2018     tw    lw       hw  M/(V.lw)     hw/lw  P/(Ag.fc)  \\\n",
      "0                  0.0  150.0  1000   2200.0      2.20  2.200000       0.00   \n",
      "1                  0.0  150.0  1400   2000.0      1.43  1.428571       0.01   \n",
      "2                  0.0  150.0  1400   2000.0      1.43  1.428571       0.01   \n",
      "3                  0.0  127.0  1625  12000.0      7.38  7.384615       0.10   \n",
      "4                  0.0  100.0   700   1600.0      2.50  2.285714       0.15   \n",
      "\n",
      "     fc      Agb        Ag    Agb/Ag   ρbl.fybl  ρsh.fysh    ρl.fyl    ρt.fyt  \\\n",
      "0  30.5  30000.0  150000.0  0.200000   5.652500  7.395000  2.847500  3.740000   \n",
      "1  46.8      0.0  210000.0  0.000000   0.000000  0.000000  4.410368  2.021229   \n",
      "2  46.6      0.0  210000.0  0.000000   0.000000  0.000000  7.725619  2.021229   \n",
      "3  49.0  77140.0  309093.0  0.249569   2.956163  2.667677  1.219476  1.177428   \n",
      "4  27.4  10000.0   70000.0  0.142857  14.732880  0.000000  2.673600  2.655481   \n",
      "\n",
      "   v_test  failure_mode  \n",
      "0  155.15           3.0  \n",
      "1  666.82           3.0  \n",
      "2  787.40           1.0  \n",
      "3  144.75           3.0  \n",
      "4  143.15           2.0  \n",
      "训练集样本数： 397\n",
      "测试集样本数： 100\n",
      "输入特征数： 15\n",
      "目标类别数： 3\n",
      "训练第 1 个子模型...\n",
      "训练第 2 个子模型...\n",
      "训练第 3 个子模型...\n",
      "训练第 4 个子模型...\n",
      "训练第 5 个子模型...\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "4/4 [==============================] - 0s 2ms/step\n",
      "集成模型准确率： 0.42\n",
      "混淆矩阵：\n",
      "[[42  0  0]\n",
      " [29  0  0]\n",
      " [29  0  0]]\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59        42\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.42       100\n",
      "   macro avg       0.14      0.33      0.20       100\n",
      "weighted avg       0.18      0.42      0.25       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15842\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\15842\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\15842\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# -----------------------------\n",
    "# 1. 数据加载与预处理\n",
    "# -----------------------------\n",
    "# 从 Excel 文件加载数据\n",
    "data = pd.read_excel(\"database.xlsx\")\n",
    "\n",
    "# 输出数据预览，检查列名称\n",
    "print(\"数据预览：\")\n",
    "print(data.head())\n",
    "\n",
    "# 定义特征和目标变量的列名称（请根据实际数据修改）\n",
    "feature_cols = ['tw', 'lw', 'hw', 'M/(V.lw)', 'hw/lw', 'P/(Ag.fc)', 'fc', 'Agb', 'Ag', 'Agb/Ag', 'ρbl.fybl', 'ρsh.fysh', 'ρl.fyl', 'ρt.fyt', 'v_test']\n",
    "target_col = \"failure_mode\"\n",
    "\n",
    "# 分离特征和目标变量\n",
    "X = data[feature_cols].values\n",
    "y = data[target_col].values\n",
    "\n",
    "# 对输入特征进行归一化处理，将特征缩放到[-1, 1]区间\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 对目标变量进行独热编码（若目标为字符串类型）\n",
    "y_encoded = pd.get_dummies(y).values\n",
    "\n",
    "# 划分训练集和测试集（80%训练，20%测试），使用 stratify 保持类别比例\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 输出数据维度以确认处理无误\n",
    "print(\"训练集样本数：\", X_train.shape[0])\n",
    "print(\"测试集样本数：\", X_test.shape[0])\n",
    "print(\"输入特征数：\", X_train.shape[1])\n",
    "print(\"目标类别数：\", y_train.shape[1])\n",
    "\n",
    "# -----------------------------\n",
    "# 2. 构建基础模型函数\n",
    "# -----------------------------\n",
    "def build_base_model(input_dim, output_dim):\n",
    "    \"\"\"\n",
    "    构建一个包含5层隐藏层的深度神经网络模型\n",
    "    参数:\n",
    "        input_dim: 输入特征数\n",
    "        output_dim: 输出类别数\n",
    "    返回:\n",
    "        model: 编译后的Keras模型\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    # 第一隐藏层，40个神经元，激活函数Tanh\n",
    "    model.add(Dense(40, activation='tanh', input_dim=input_dim))\n",
    "    model.add(Dropout(0.02))\n",
    "    # 第二隐藏层，80个神经元\n",
    "    model.add(Dense(80, activation='tanh'))\n",
    "    # 第三隐藏层，60个神经元\n",
    "    model.add(Dense(60, activation='tanh'))\n",
    "    # 第四隐藏层，40个神经元\n",
    "    model.add(Dense(40, activation='tanh'))\n",
    "    # 第五隐藏层，25个神经元\n",
    "    model.add(Dense(25, activation='tanh'))\n",
    "    # 输出层，输出类别数（采用softmax激活，适用于多分类任务）\n",
    "    model.add(Dense(output_dim, activation='softmax'))\n",
    "    \n",
    "    # 使用Adam优化器，学习率设置为0.01（可根据需要调节）\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 模型平均集成 (MAE)\n",
    "# -----------------------------\n",
    "ensemble_size = 5  # 可根据需要调整集成模型的数量\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "base_models = []\n",
    "\n",
    "# 训练多个基础模型，每个模型因随机初始化及数据拆分不同会有一定差异\n",
    "for i in range(ensemble_size):\n",
    "    print(f\"训练第 {i+1} 个子模型...\")\n",
    "    model = build_base_model(input_dim, output_dim)\n",
    "    # 此处训练轮次和批次大小可根据实际情况进行调节\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1, verbose=0)\n",
    "    base_models.append(model)\n",
    "\n",
    "# 定义集成预测函数：对每个子模型的预测结果取平均\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    avg_prediction = np.mean(predictions, axis=0)\n",
    "    return avg_prediction\n",
    "\n",
    "# -----------------------------\n",
    "# 4. 模型评估\n",
    "# -----------------------------\n",
    "# 在测试集上获得集成模型预测结果\n",
    "ensemble_output = ensemble_predict(base_models, X_test)\n",
    "y_pred = np.argmax(ensemble_output, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 计算准确率\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"集成模型准确率：\", acc)\n",
    "\n",
    "# 输出混淆矩阵\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "print(\"混淆矩阵：\")\n",
    "print(conf_mat)\n",
    "\n",
    "# 输出详细的分类报告，包括精度、召回率、F1分数等\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"分类报告：\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c33e2c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据预览：\n",
      "                      Paper No                   Specimen  \\\n",
      "0  Abdulridha & Palermo (2017)                      W1-SR   \n",
      "1      [114] Adajar et al.1995                       RCW1   \n",
      "2                          NaN                       RCW3   \n",
      "3             [98] Adebar,2007  High-Rise Core Wall (265)   \n",
      "4            [26] Alarcon,2014                    W1 (49)   \n",
      "\n",
      "   conformity_tbec2018     tw    lw       hw  M/(V.lw)     hw/lw  P/(Ag.fc)  \\\n",
      "0                  0.0  150.0  1000   2200.0      2.20  2.200000       0.00   \n",
      "1                  0.0  150.0  1400   2000.0      1.43  1.428571       0.01   \n",
      "2                  0.0  150.0  1400   2000.0      1.43  1.428571       0.01   \n",
      "3                  0.0  127.0  1625  12000.0      7.38  7.384615       0.10   \n",
      "4                  0.0  100.0   700   1600.0      2.50  2.285714       0.15   \n",
      "\n",
      "     fc      Agb        Ag    Agb/Ag   ρbl.fybl  ρsh.fysh    ρl.fyl    ρt.fyt  \\\n",
      "0  30.5  30000.0  150000.0  0.200000   5.652500  7.395000  2.847500  3.740000   \n",
      "1  46.8      0.0  210000.0  0.000000   0.000000  0.000000  4.410368  2.021229   \n",
      "2  46.6      0.0  210000.0  0.000000   0.000000  0.000000  7.725619  2.021229   \n",
      "3  49.0  77140.0  309093.0  0.249569   2.956163  2.667677  1.219476  1.177428   \n",
      "4  27.4  10000.0   70000.0  0.142857  14.732880  0.000000  2.673600  2.655481   \n",
      "\n",
      "   v_test  failure_mode  \n",
      "0  155.15           3.0  \n",
      "1  666.82           3.0  \n",
      "2  787.40           1.0  \n",
      "3  144.75           3.0  \n",
      "4  143.15           2.0  \n",
      "训练第 1 个子模型...\n",
      "子模型 1, Epoch 30/150, Loss: nan\n",
      "子模型 1, Epoch 60/150, Loss: nan\n",
      "子模型 1, Epoch 90/150, Loss: nan\n",
      "子模型 1, Epoch 120/150, Loss: nan\n",
      "子模型 1, Epoch 150/150, Loss: nan\n",
      "训练第 2 个子模型...\n",
      "子模型 2, Epoch 30/150, Loss: nan\n",
      "子模型 2, Epoch 60/150, Loss: nan\n",
      "子模型 2, Epoch 90/150, Loss: nan\n",
      "子模型 2, Epoch 120/150, Loss: nan\n",
      "子模型 2, Epoch 150/150, Loss: nan\n",
      "训练第 3 个子模型...\n",
      "子模型 3, Epoch 30/150, Loss: nan\n",
      "子模型 3, Epoch 60/150, Loss: nan\n",
      "子模型 3, Epoch 90/150, Loss: nan\n",
      "子模型 3, Epoch 120/150, Loss: nan\n",
      "子模型 3, Epoch 150/150, Loss: nan\n",
      "训练第 4 个子模型...\n",
      "子模型 4, Epoch 30/150, Loss: nan\n",
      "子模型 4, Epoch 60/150, Loss: nan\n",
      "子模型 4, Epoch 90/150, Loss: nan\n",
      "子模型 4, Epoch 120/150, Loss: nan\n",
      "子模型 4, Epoch 150/150, Loss: nan\n",
      "训练第 5 个子模型...\n",
      "子模型 5, Epoch 30/150, Loss: nan\n",
      "子模型 5, Epoch 60/150, Loss: nan\n",
      "子模型 5, Epoch 90/150, Loss: nan\n",
      "子模型 5, Epoch 120/150, Loss: nan\n",
      "子模型 5, Epoch 150/150, Loss: nan\n",
      "集成模型准确率： 0.42\n",
      "混淆矩阵：\n",
      "[[42  0  0]\n",
      " [29  0  0]\n",
      " [29  0  0]]\n",
      "分类报告：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59        42\n",
      "           1       0.00      0.00      0.00        29\n",
      "           2       0.00      0.00      0.00        29\n",
      "\n",
      "    accuracy                           0.42       100\n",
      "   macro avg       0.14      0.33      0.20       100\n",
      "weighted avg       0.18      0.42      0.25       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15842\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\15842\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\15842\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 设备设置\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# -----------------------------\n",
    "# 1. 数据加载与预处理\n",
    "# -----------------------------\n",
    "data = pd.read_excel(\"database.xlsx\")\n",
    "print(\"数据预览：\")\n",
    "print(data.head())\n",
    "\n",
    "# 定义特征和目标变量的列名（请根据实际数据修改）\n",
    "feature_cols = ['tw', 'lw', 'hw', 'M/(V.lw)', 'hw/lw', 'P/(Ag.fc)', 'fc', 'Agb', 'Ag', 'Agb/Ag', 'ρbl.fybl', 'ρsh.fysh', 'ρl.fyl', 'ρt.fyt', 'v_test']\n",
    "target_col = \"failure_mode\"\n",
    "\n",
    "X = data[feature_cols].values\n",
    "y = data[target_col].values\n",
    "\n",
    "# 归一化特征到[-1,1]\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 对目标变量进行独热编码\n",
    "y_encoded = pd.get_dummies(y).values\n",
    "\n",
    "# 划分训练集和测试集（80%训练，20%测试）\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# 将数据转换为Tensor\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "# 注意：这里将one-hot目标转换为类别标签（整数）以便使用CrossEntropyLoss\n",
    "y_train_labels = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long).to(device)\n",
    "y_test_labels = torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long).to(device)\n",
    "\n",
    "# -----------------------------\n",
    "# 2. 自定义 Dataset 与 DataLoader\n",
    "# -----------------------------\n",
    "class FailureModeDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y  # 这里y为类别标签\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = FailureModeDataset(X_train_tensor, y_train_labels)\n",
    "test_dataset = FailureModeDataset(X_test_tensor, y_test_labels)\n",
    "\n",
    "# 计算训练集各类别样本数量，进而计算类别权重\n",
    "unique_classes, counts = np.unique(y_train_labels.cpu().numpy(), return_counts=True)\n",
    "class_weights = 1. / counts\n",
    "weights = [class_weights[label] for label in y_train_labels.cpu().numpy()]\n",
    "weights = torch.DoubleTensor(weights)\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. 定义5层神经网络（改进版）\n",
    "# -----------------------------\n",
    "class DeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DeepNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 40)\n",
    "        self.fc2 = nn.Linear(40, 80)\n",
    "        self.fc3 = nn.Linear(80, 60)\n",
    "        self.fc4 = nn.Linear(60, 40)\n",
    "        self.fc5 = nn.Linear(40, 25)\n",
    "        self.output = nn.Linear(25, output_dim)\n",
    "        self.activation = nn.ReLU()  # 使用ReLU激活函数\n",
    "        self.dropout = nn.Dropout(0.2)  # 提高Dropout比例\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.activation(self.fc4(x))\n",
    "        x = self.activation(self.fc5(x))\n",
    "        x = self.output(x)\n",
    "        return x  # 注意：这里返回的原始logits，交叉熵内部会处理softmax\n",
    "\n",
    "# -----------------------------\n",
    "# 4. 训练多个子模型（MAE）\n",
    "# -----------------------------\n",
    "ensemble_size = 5\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = len(unique_classes)  # 输出类别数\n",
    "models = []\n",
    "\n",
    "# 计算类别权重Tensor，用于损失函数\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "for i in range(ensemble_size):\n",
    "    print(f\"训练第 {i+1} 个子模型...\")\n",
    "    model = DeepNeuralNetwork(input_dim, output_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    # 使用带权重的交叉熵损失\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "    # 学习率调度器：每30个epoch降低学习率\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.5)\n",
    "    epochs = 150\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * X_batch.size(0)\n",
    "        scheduler.step()\n",
    "        # 每30个epoch打印一次平均损失\n",
    "        if (epoch+1) % 30 == 0:\n",
    "            avg_loss = running_loss / len(train_dataset)\n",
    "            print(f\"子模型 {i+1}, Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "    models.append(model)\n",
    "\n",
    "# -----------------------------\n",
    "# 5. 集成预测与模型评估\n",
    "# -----------------------------\n",
    "def ensemble_predict(models, loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for X_batch, y_batch in loader:\n",
    "        batch_preds = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                outputs = model(X_batch)\n",
    "                # 取softmax后预测类别\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                batch_preds.append(probs.cpu().numpy())\n",
    "        avg_preds = np.mean(batch_preds, axis=0)\n",
    "        all_preds.append(avg_preds)\n",
    "        all_labels.append(y_batch.cpu().numpy())\n",
    "    return np.concatenate(all_preds), np.concatenate(all_labels)\n",
    "\n",
    "ensemble_output, y_true = ensemble_predict(models, test_loader)\n",
    "y_pred = np.argmax(ensemble_output, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(\"集成模型准确率：\", acc)\n",
    "\n",
    "conf_mat = confusion_matrix(y_true, y_pred)\n",
    "print(\"混淆矩阵：\")\n",
    "print(conf_mat)\n",
    "\n",
    "class_report = classification_report(y_true, y_pred)\n",
    "print(\"分类报告：\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395011c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
